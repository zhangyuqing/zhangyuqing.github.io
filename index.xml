<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stars &amp; Sea</title>
    <link>/</link>
    <description>Recent content on Stars &amp; Sea</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Predicting Online Shoppers Purchasing Intention with H2O </title>
      <link>/2019/09/predicting-online-shoppers-purchasing-intention-with-h2o/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/predicting-online-shoppers-purchasing-intention-with-h2o/</guid>
      <description>Introduction Analyzing User Behavior in E-commerce E-commerce, the activity of buying and selling products online, is one of the many fields revolutionized by data science. One of the essential goals for e-commerce companies is to increase purchase conversion rates, i.e. the percentage of website visiters who complete the purchase at online stores. To achieve this goal, e-commerce companies as well as researchers in academia have devoted efforts in analyzing and modeling the behaviors of webpage users.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>/publications/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/publications/</guid>
      <description>Journal Papers 2019  McQuerry, J.A., Jenkins, D.F., Yost, S.E., Zhang, Y., Schmolze, D., Johnson, W.E., Yuan, Y. and Bild, A.H., (2019). Pathway activity profiling of growth factor receptor network and stemness pathways differentiates metaplastic breast cancer histological subtypes. BMC cancer Zhang, Y., Johnson, W. E., &amp;amp; Parmigiani, G. (2019). Robustifying genomic classifiers to batch effects via ensemble learning. bioRxiv   2018  Zhang, Y., Bernau, C., Parmigiani, G., &amp;amp; Waldron, L.</description>
    </item>
    
    <item>
      <title>Lung Cancer Detection from CT Scan Images Using DCNNs</title>
      <link>/2019/09/lung-cancer-detection-from-ct-scan-images-using-dcnns/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/lung-cancer-detection-from-ct-scan-images-using-dcnns/</guid>
      <description>Poster
Report
Code on GitHub Repository
About the Project: Kaggle Data Science Bowl 2017</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/projects/</link>
      <pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/projects/</guid>
      <description>Completed  Lung cancer classification from CT scan images using deep convolutional neural networks  - 2017 Data Science Bowl Kaggle Competition
Project report  Implemented U-Net with Python and Tensorflow according to literature for nodule segmentation Developed deep convolutional neural networks for lung cancer classification Applied batch normalization, drop-out layers, and tuned parameters to improve prediction accuracy Augmented training data by random cropping and merging the training set with images from public databases of CT scans Achieved performance comparable to top-50 out of 394 participating teams  A multivariate Gaussian Network for detection of multiple perturbations in gene regulartory networks</description>
    </item>
    
    <item>
      <title>Personal</title>
      <link>/personal/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/personal/</guid>
      <description>This is me in Hokkaido, Japan. Hello World!
  
My name, Yuqing (雨晴), is pronounced y-oo-ching. It means the sky clears up after rain.
You’ve come to my place to write down the things I learn, fun projects I work on, events of my life and random thoughts. The title of my website, Stars and Sea (星辰大海), is quoted from Yuandong Tian, an accomplished research scientist in deep learning.</description>
    </item>
    
    <item>
      <title>开会随感</title>
      <link>/2019/08/%E5%BC%80%E4%BC%9A%E9%9A%8F%E6%84%9F/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/%E5%BC%80%E4%BC%9A%E9%9A%8F%E6%84%9F/</guid>
      <description>JSM memory
  前几天在 JSM 有幸听了 RStudio 谢益辉的讲座，并攀谈了几句。益辉大神听说我在用 blogdown，就说，希望我把自己的主页和博客坚持更新下去。他说这话的时候，我因为各种原因已经把最新一篇博客拖了两个月，有点心虚。说实话，我不擅长写作。早在高中的时候，我的作文就总被语文老师吐槽中心思想不明确。那时我比现在更多思多虑，有很多想表达的东西，奈何语言和逻辑水平不过关，很多纠缠在一起没理清楚的思绪就挤在一篇文章里，一股脑发泄出来。我没想明白要说什么，读者看了估计也觉得云里雾里。后来大学学了数学，整天在定义和符号里转圈，就更是把语文还给老师了。按说我不该再有兴致写东西了（一些中学的老友可能还记得我的老博客）。然而技术对人的影响就是很神奇。偏偏在放弃写作多年后，我偶然了解到益辉开发的 blogdown 。于是就这样，在强化自己敲代码水平的过程中，又重新有了写点什么的念头。
扯远了。刚才说把最新一篇博客拖了两个月，是因为这两个月来我在马不停蹄的做事。之前在做的研究项目都接近收尾，有一个最近已经成稿放到了 bioRxiv上， 另一个项目的文章也正在写。此外，我应朋友邀请，给大数 NGO 做了志愿者，写了有生以来第一篇微信公众号文章。再有就是去开了两次会，一次是五月底在华盛顿州贝尔维尤的 SDSS，另一次就是刚刚过去，在科罗拉多丹佛市的 JSM。总的来看，这个夏天我过得很充实，虽然和计划有出入，但也算做成了一些事情。
两次去开会的经历最让我有感触。
读博这几年，我不常去开会，总觉得还没做出成果，去会上演讲也没什么底气。这两次去了才意识到，开会虽然有展示自己学术成果的成分，但 networking 更重要。去和人交谈，了解别人在做的事，有益于更好地反思和矫正自己在走的路。尤其对于像我这样一个不务正业，总是被其他领域的“绿草” (the grass is greener on the other side) 吸引的博士生，去开会很有好处。像是在 SDSS 上，我就听到了许多关于业界 production machine learning 的内容，包括 Kubeflow, TFX Tensorflow，和 H2O。后来还幸运地以此为契机，邀请到 H2O.ai 的 Dr. Erin LeDell 来大数做讲座。在 JSM 上听到的讲座更是有意思，从严谨的方法创新（连续时间 MCMC 及其在贝叶斯推断中的应用），到用经典方法处理新问题（用 PageRank 算法分析 Reddit 网络数据找高分播主），内容五花八门。
参加这些讲座，也不是说听过就真能学会新知识。只是我明显感觉到自己的技能与社会需求的差距，因而产生了强烈的危机感。有个关于 PhD 的段子，大意是说博士越读知识面会越窄，直到最后，达到 “know everything about nothing” 的境地。这本无可厚非——毕竟博士训练的目的就是培养精通某一领域的专才。然而从个人发展的角度，过于专注自己的研究领域而忽略周围的环境不太好，容易让人失了定位。
学术界的革新可以发生得很快。比如去年声称横扫自然语言处理各项任务的 BERT ，仅这个夏天短短几个月，就先被 XLNet 超越，后者又在一个半月内被百度 ERNIE 2.</description>
    </item>
    
    <item>
      <title>ML Summary Series (2) - Bias-Variance Tradeoff</title>
      <link>/2019/06/ml-summary-series-2---bias-variance-tradeoff/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/ml-summary-series-2---bias-variance-tradeoff/</guid>
      <description>We are all familiar with the workflow of supervised learning: fit models on training data, and make predictions on the test set. But why should performance of models in the training set tell us anything about that in the test set? Is model performance always generalizable to new data? Learning theory aims to address these questions under a general, abstract formulation of the supervised learning problem, without specifying details like the type of model or the source of data.</description>
    </item>
    
    <item>
      <title>ML Summary Series (1) - Concepts</title>
      <link>/2019/05/ml-summary-series-1---concepts/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/ml-summary-series-1---concepts/</guid>
      <description>Machine learning (ML) is by no means new to me. I took ML courses in college and in grad school. In college, I was also in a study group where we went through Bishop’s PRML chapter by chapter. Later when I became a PhD, I use machine learning in plenty of projects, from the visualization of data after dimensional reduction through PCA, to building prediction models with logistic regression, random forest, support vector machines, etc.</description>
    </item>
    
    <item>
      <title>Welcome to Yuqing&#39;s Stars and Sea</title>
      <link>/home/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/home/</guid>
      <description>Scientist with excellent communication skills, fast learner and critical thinker, dedicated, detail-oriented, analytical, and organized. I am passionate about using my expertise in statistical learning and programming to deliver game-changing knowledge from data.
I received B.S. in Applied Math from Peking University, after which I started graduate training at Boston University, working in Computational Biomedicine (CBM), while jointly advised by Evan and Giovanni. Now I am about to enter (hopefully) the final year of my PhD.</description>
    </item>
    
    <item>
      <title>Software</title>
      <link>/software/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/software/</guid>
      <description>R/Bioconductor packages simulatorZ Zhang Y, Bernau C, Waldron L (2018). simulatorZ: Simulator for Collections of Independent Genomic Data Sets. R package version 1.16.0.
 reference-batch ComBat Leek JT, Johnson WE, Parker HS, Fertig EJ, Jaffe AE, Storey JD, Zhang Y, Torres LC (2019). sva: Surrogate Variable Analysis. R package version 3.30.1.
  </description>
    </item>
    
  </channel>
</rss>